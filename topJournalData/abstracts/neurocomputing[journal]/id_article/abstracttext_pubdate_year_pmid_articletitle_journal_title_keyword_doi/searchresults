{"articleID":{"0":0,"1":1,"2":2,"3":3,"4":4,"5":5,"6":6,"7":7,"8":8,"9":9,"10":10,"11":11,"12":12,"13":13,"14":14,"15":15,"16":16,"17":17,"18":18,"19":19,"20":20,"21":21,"22":22,"23":23,"24":24,"25":25,"26":26,"27":27,"28":28,"29":29,"30":30,"31":31,"32":32,"33":33,"34":34,"35":35,"36":36,"37":37,"38":38,"39":39,"40":40,"41":41,"42":42,"43":43,"44":44,"45":45,"46":46,"47":47,"48":48,"49":49,"50":50,"51":51,"52":52,"53":53,"54":54,"55":55,"56":56,"57":57,"58":58,"59":59,"60":60,"61":61,"62":62,"63":63,"64":64,"65":65,"66":66,"67":67,"68":68,"69":69,"70":70,"71":71,"72":72,"73":73,"74":74,"75":75,"76":76,"77":77,"78":78,"79":79,"80":80,"81":81,"82":82,"83":83,"84":84,"85":85},"abstracttext":{"0":null,"1":null,"2":"The front-line imaging modalities computed tomography (CT) and X-ray play important roles for triaging COVID patients. Thoracic CT has been accepted to have higher sensitivity than a chest X-ray for COVID diagnosis. Considering the limited access to resources (both hardware and trained personnel) and issues related to decontamination, CT may not be ideal for triaging suspected subjects. Artificial intelligence (AI) assisted X-ray based application for triaging and monitoring require experienced radiologists to identify COVID patients in a timely manner with the additional ability to delineate and quantify the disease region is seen as a promising solution for widespread clinical use. Our proposed solution differs from existing solutions presented by industry and academic communities. We demonstrate a functional AI model to triage by classifying and segmenting a single chest X-ray image, while the AI model is trained using both X-ray and CT data. We report on how such a multi-modal training process improves the solution compared to single modality (X-ray only) training. The multi-modal solution increases the AUC (area under the receiver operating characteristic curve) from 0.89 to 0.93 for a binary classification between COVID-19 and non-COVID-19 cases. It also positively impacts the Dice coefficient (0.59 to 0.62) for localizing the COVID-19 pathology. To compare the performance of experienced readers to the AI model, a reader study is also conducted. The AI model showed good consistency with respect to radiologists. The DICE score between two radiologists on the COVID group was 0.53 while the AI had a DICE value of 0.52 and 0.55 when compared to the segmentation done by the two radiologists separately. From a classification perspective, the AUCs of two readers was 0.87 and 0.81 while the AUC of the AI is 0.93 based on the reader study dataset. We also conducted a generalization study by comparing our method to the-state-art methods on independent datasets. The results show better performance from the proposed method. Leveraging multi-modal information for the development benefits the single-modal inferencing.","3":"Pathology tissue slides are taken as the gold standard for the diagnosis of most cancer diseases. Automatic pathology slide diagnosis is still a challenging task for researchers because of the high-resolution, significant morphological variation, and ambiguity between malignant and benign regions in whole slide images (WSIs). In this study, we introduce a general framework to automatically diagnose different types of WSIs via unit stochastic selection and attention fusion. For example, a unit can denote a patch in a histopathology slide or a cell in a cytopathology slide. To be specific, we first train a unit-level convolutional neural network (CNN) to perform two tasks: constructing feature extractors for the units and for estimating a unit's non-benign probability. Then we use our novel stochastic selection algorithm to choose a small subset of units that are most likely to be non-benign, referred to as the Units Of Interest (UOI), as determined by the CNN. Next, we use the attention mechanism to fuse the representations of the UOI to form a fixed-length descriptor for the WSI's diagnosis. We evaluate the proposed framework on three datasets: histological thyroid frozen sections, histological colonoscopy tissue slides, and cytological cervical pap smear slides. The framework achieves diagnosis accuracies higher than 0.8 and AUC values higher than 0.85 in all three applications. Experiments demonstrate the generality and effectiveness of the proposed framework and its potentiality for clinical applications.","4":"The Covid-19 pandemic is the defining global health crisis of our time. Chest X-Rays (CXR) have been an important imaging modality for assisting in the diagnosis and management of hospitalised Covid-19 patients. However, their interpretation is time intensive for radiologists. Accurate computer aided systems can facilitate early diagnosis of Covid-19 and effective triaging. In this paper, we propose a fuzzy logic based deep learning (DL) approach to differentiate between CXR images of patients with Covid-19 pneumonia and with interstitial pneumonias not related to Covid-19. The developed model here, referred to as CovNNet, is used to extract some relevant features from CXR images, combined with fuzzy images generated by a fuzzy edge detection algorithm. Experimental results show that using a combination of CXR and fuzzy features, within a deep learning approach by developing a deep network inputed to a Multilayer Perceptron (MLP), results in a higher classification performance (accuracy rate up to 81%), compared to benchmark deep learning approaches. The approach has been validated through additional datasets which are continously generated due to the spread of the virus and would help triage patients in acute settings. A permutation analysis is carried out, and a simple occlusion methodology for explaining decisions is also proposed. The proposed pipeline can be easily embedded into present clinical decision support systems.","5":"The outbreak of the coronavirus disease 2019 (COVID-19) has now spread throughout the globe infecting over 150 million people and causing the death of over 3.2 million people. Thus, there is an urgent need to study the dynamics of epidemiological models to gain a better understanding of how such diseases spread. While epidemiological models can be computationally expensive, recent advances in machine learning techniques have given rise to neural networks with the ability to learn and predict complex dynamics at reduced computational costs. Here we introduce two digital twins of a SEIRS model applied to an idealised town. The SEIRS model has been modified to take account of spatial variation and, where possible, the model parameters are based on official virus spreading data from the UK. We compare predictions from one digital twin based on a data-corrected Bidirectional Long Short-Term Memory network with predictions from another digital twin based on a predictive Generative Adversarial Network. The predictions given by these two frameworks are accurate when compared to the original SEIRS model data. Additionally, these frameworks are data-agnostic and could be applied to towns, idealised or real, in the UK or in other countries. Also, more compartments could be included in the SEIRS model, in order to study more realistic epidemiological behaviour.","6":"COVID-19 was declared a global pandemic by the World Health Organisation (WHO) on 11th March 2020. Many researchers have, in the past, attempted to predict a COVID outbreak and its effect. Some have regarded time-series variables as primary factors which can affect the onset of infectious diseases like influenza and severe acute respiratory syndrome (SARS). In this study, we have used public datasets provided by the European Centre for Disease Prevention and Control for developing a prediction model for the spread of the COVID-19 outbreak to and throughout Malaysia, Morocco and Saudi Arabia. We have made use of certain effective deep learning (DL) models for this purpose. We assessed some specific major features for predicting the trend of the existing COVID-19 outbreak in these three countries. In this study, we also proposed a DL approach that includes recurrent neural network (RNN) and long short-term memory (LSTM) networks for predicting the probable numbers of COVID-19 cases. The LSTM models showed a 98.58% precision accuracy while the RNN models showed a 93.45% precision accuracy. Also, this study compared the number of coronavirus cases and the number of resulting deaths in Malaysia, Morocco and Saudi Arabia. Thereafter, we predicted the number of confirmed COVID-19 cases and deaths for a subsequent seven days. In this study, we presented their predictions using the data that was available up to December 3rd, 2020.","7":"In this work, certain aspects of the structure of the overlapping groups of neurons encoding specific signals are examined. Individual neurons are assumed to respond stochastically to input signal. Identification of a particular signal is assumed to result from the aggregate activity of a group of neurons, which we call information pathway. Conditions for definite response and for non-interference of pathways are derived. These conditions constrain the response properties of individual neurons and the allowed overlap among pathways. Under these constrains, and under the simplifying assumption that all pathways have similar structure, the information capacity of the system is derived. Furthermore, we show that there is a definite advantage in the information capacity if pathway neurons areinterspersed among the neuron assembly.","8":"The unprecedented surge of a novel coronavirus in the month of December 2019, named as COVID-19 by the World Health organization has caused a serious impact on the health and socioeconomic activities of the public all over the world. Since its origin, the number of infected and deceased cases has been growing exponentially in almost all the affected countries of the world. The rapid spread of the novel coronavirus across the world results in the scarcity of medical resources and overburdened hospitals. As a result, the researchers and technocrats are continuously working across the world for the inculcation of efficient strategies which may assist the government and healthcare system in controlling and managing the spread of the COVID-19 pandemic. Therefore, this study provides an extensive review of the ongoing strategies such as diagnosis, prediction, drug and vaccine development and preventive measures used in combating the COVID-19 along with technologies used and limitations. Moreover, this review also provides a comparative analysis of the distinct type of data, emerging technologies, approaches used in diagnosis and prediction of COVID-19, statistics of contact tracing apps, vaccine production platforms used in the COVID-19 pandemic. Finally, the study highlights some challenges and pitfalls observed in the systematic review which may assist the researchers to develop more efficient strategies used in controlling and managing the spread of COVID-19.","9":"The outbreak and rapid spread of coronavirus disease 2019 (COVID-19) has had a huge impact on the lives and safety of people around the world. Chest CT is considered an effective tool for the diagnosis and follow-up of COVID-19. For faster examination, automatic COVID-19 diagnostic techniques using deep learning on CT images have received increasing attention. However, the number and category of existing datasets for COVID-19 diagnosis that can be used for training are limited, and the number of initial COVID-19 samples is much smaller than the normal's, which leads to the problem of class imbalance. It makes the classification algorithms difficult to learn the discriminative boundaries since the data of some classes are rich while others are scarce. Therefore, training robust deep neural networks with imbalanced data is a fundamental challenging but important task in the diagnosis of COVID-19. In this paper, we create a challenging clinical dataset (named COVID19-Diag) with category diversity and propose a novel imbalanced data classification method using deep supervised learning with a self-adaptive auxiliary loss (DSN-SAAL) for COVID-19 diagnosis. The loss function considers both the effects of data overlap between CT slices and possible noisy labels in clinical datasets on a multi-scale, deep supervised network framework by integrating the effective number of samples and a weighting regularization item. The learning process jointly and automatically optimizes all parameters over the deep supervised network, making our model generally applicable to a wide range of datasets. Extensive experiments are conducted on COVID19-Diag and three public COVID-19 diagnosis datasets. The results show that our DSN-SAAL outperforms the state-of-the-art methods and is effective for the diagnosis of COVID-19 in varying degrees of data imbalance.","10":"Differential network analysis has become an important approach in identifying driver genes in development and disease. However, most studies capture only local features of the underlying gene-regulatory network topology. These approaches are vulnerable to noise and other changes which mask driver-gene activity. Therefore, methods are urgently needed which can separate the impact of true regulatory elements from stochastic changes and downstream effects. We propose the differential network flow (DNF) method to identify key regulators of progression in development or disease. Given the network representation of consecutive biological states, DNF quantifies the essentiality of each node by differences in the distribution of network flow, which are capable of capturing comprehensive topological differences from local to global feature domains. DNF achieves more accurate driver-gene identification than other state-of-the-art methods when applied to four human datasets from The Cancer Genome Atlas and three single-cell RNA-seq datasets of murine neural and hematopoietic differentiation. Furthermore, we predict key regulators of crosstalk between separate networks underlying both neuronal differentiation and the progression of neurodegenerative disease, among which APP is predicted as a driver gene of neural stem cell differentiation. Our method is a new approach for quantifying the essentiality of genes across networks of different biological states.","11":"The early detection of infection is significant for the fight against the ongoing COVID-19 pandemic. Chest X-ray (CXR) imaging is an efficient screening technique via which lung infections can be detected. This paper aims to distinguish COVID-19 positive cases from the other four classes, including normal, tuberculosis (TB), bacterial pneumonia (BP), and viral pneumonia (VP), using CXR images. The existing COVID-19 classification researches have achieved some successes with deep learning techniques while sometimes lacking interpretability and generalization ability. Hence, we propose a two-stage classification method MANet to address these issues in computer-aided COVID-19 diagnosis. Particularly, a segmentation model predicts the masks for all CXR images to extract their lung regions at the first stage. A followed classification CNN at the second stage then classifies the segmented CXR images into five classes based only on the preserved lung regions. In this segment-based classification task, we propose the mask attention mechanism (MA) which uses the predicted masks at the first stage as spatial attention maps to adjust the features of the CNN at the second stage. The MA spatial attention maps for features calculate the percentage of masked pixels in their receptive fields, suppressing the feature values based on the overlapping rates between their receptive fields and the segmented lung regions. In evaluation, we segment out the lung regions of all CXR images through a UNet with ResNet backbone, and then perform classification on the segmented CXR images using four classic CNNs with or without MA, including ResNet34, ResNet50, VGG16, and Inceptionv3. The experimental results illustrate that the classification models with MA have higher classification accuracy, more stable training process, and better interpretability and generalization ability than those without MA. Among the evaluated classification models, ResNet50 with MA achieves the highest average test accuracy of 96.32 %  in three runs, and the highest one is 97.06 %  . Meanwhile, the attention heat maps visualized by Grad-CAM indicate that models with MA make more reliable predictions based on the pathological patterns in lung regions. This further presents the potential of MANet to provide clinicians with diagnosis assistance.","12":"The widely spreading COVID-19 has caused thousands of hundreds of mortalities over the world in the past few months. Early diagnosis of the virus is of great significance for both of infected patients and doctors providing treatments. Chest Computerized tomography (CT) screening is one of the most straightforward techniques to detect pneumonia which was caused by the virus and thus to make the diagnosis. To facilitate the process of diagnosing COVID-19, we therefore developed a graph convolutional neural network ResGNet-C under ResGNet framework to automatically classify lung CT images into normal and confirmed pneumonia caused by COVID-19. In ResGNet-C, two by-products named NNet-C, ResNet101-C that showed high performance on detection of COVID-19 are simultaneously generated as well. Our best model ResGNet-C achieved an averaged accuracy at 0.9662 with an averaged sensitivity at 0.9733 and an averaged specificity at 0.9591 using five cross-validations on the dataset, which is comprised of 296 CT images. To our best knowledge, this is the first attempt at integrating graph knowledge into the COVID-19 classification task. Graphs are constructed according to the Euclidean distance between features extracted by our proposed ResNet101-C and then are encoded with the features to give the prediction results of CT images. Besides the high-performance system, which surpassed all state-of-the-art methods, our proposed graph construction method is simple, transferrable yet quite helpful for improving the performance of classifiers, as can be justified by the experimental results.","13":"Simulations of neural networks can be used to study the direct effect of internal or external changes on brain dynamics. However, some changes are not immediate but occur on the timescale of weeks, months, or years. Examples include effects of strokes, surgical tissue removal, or traumatic brain injury but also gradual changes during brain development. Simulating network activity over a long time, even for a small number of nodes, is a computational challenge. Here, we model a coupled network of human brain regions with a modified Wilson-Cowan model representing dynamics for each region and with synaptic plasticity adjusting connection weights within and between regions. Using strategies ranging from different models for plasticity, vectorization and a different differential equation solver setup, we achieved one second runtime for one second biological time.","14":"Feature selection is a critical component in supervised learning to improve model performance. Searching for the optimal feature candidates can be NP-hard. With limited data, cross-validation is widely used to alleviate overfitting, which unfortunately suffers from high computational cost. We propose a highly innovative strategy in feature selection to reduce the overfitting risk but without cross-validation. Our method selects the optimal sub-interval, i.e., region of interest (ROI), of a functional feature for functional linear regression where the response is a scalar and the predictor is a function. For each candidate sub-interval, we evaluate the overfitting risk by calculating a necessary sample size to achieve a pre-specified statistical power. Combining with a model accuracy measure, we rank these sub-intervals and select the ROI. The proposed method has been compared with other state-of-the-art feature selection methods on several reference datasets. The results show that our proposed method achieves an excellent performance in prediction accuracy and reduces computational cost substantially.","15":"Most deep language understanding models depend only on word representations, which are mainly based on language modelling derived from a large amount of raw text. These models encode distributional knowledge without considering syntactic structural information, although several studies have shown benefits of including such information. Therefore, we propose new syntactically-informed word representations (SIWRs), which allow us to enrich the pre-trained word representations with syntactic information without training language models from scratch. To obtain SIWRs, a graph-based neural model is built on top of either static or contextualised word representations such as GloVe, ELMo and BERT. The model is first pre-trained with only a relatively modest amount of task-independent data that are automatically annotated using existing syntactic tools. SIWRs are then obtained by applying the model to downstream task data and extracting the intermediate word representations. We finally replace word representations in downstream models with SIWRs for applications. We evaluate SIWRs on three information extraction tasks, namely nested named entity recognition (NER), binary and n-ary relation extractions (REs). The results demonstrate that our SIWRs yield performance gains over the base representations in these NLP tasks with 3-9% relative error reduction. Our SIWRs also perform better than fine-tuning BERT in binary RE. We also conduct extensive experiments to analyse the proposed method.","16":"This survey presents a review of state-of-the-art deep neural network architectures, algorithms, and systems in vision and speech applications. Recent advances in deep artificial neural network algorithms and architectures have spurred rapid innovation and development of intelligent vision and speech systems. With availability of vast amounts of sensor data and cloud computing for processing and training of deep neural networks, and with increased sophistication in mobile and embedded technology, the next-generation intelligent systems are poised to revolutionize personal and commercial computing. This survey begins by providing background and evolution of some of the most successful deep learning models for intelligent vision and speech systems to date. An overview of large-scale industrial research and development efforts is provided to emphasize future trends and prospects of intelligent vision and speech systems. Robust and efficient intelligent systems demand low-latency and high fidelity in resource-constrained hardware platforms such as mobile devices, robots, and automobiles. Therefore, this survey also provides a summary of key challenges and recent successes in running deep neural networks on hardware-restricted platforms, i.e. within limited memory, battery life, and processing capabilities. Finally, emerging applications of vision and speech across disciplines such as affective computing, intelligent transportation, and precision medicine are discussed. To our knowledge, this paper provides one of the most comprehensive surveys on the latest developments in intelligent vision and speech applications from the perspectives of both software and hardware systems. Many of these emerging technologies using deep neural networks show tremendous promise to revolutionize research and development for future vision and speech systems.","17":"With the rapid development of image acquisition and storage, multiple images per class are commonly available for computer vision tasks (e.g., face recognition, object detection, medical imaging, etc.). Recently, the recurrent neural network (RNN) has been widely integrated with convolutional neural networks (CNN) to perform image classification on ordered (sequential) data. In this paper, by permutating multiple images as multiple dummy orders, we generalize the ordered \"RNN+CNN\" design (longitudinal) to a novel unordered fashion, called Multi-path x-D Recurrent Neural Network (MxDRNN) for image classification. To the best of our knowledge, few (if any) existing studies have deployed the RNN framework to unordered intra-class images to leverage classification performance. Specifically, multiple learning paths are introduced in the MxDRNN to extract discriminative features by permutating input dummy orders. Eight datasets from five different fields (MNIST, 3D-MNIST, CIFAR, VGGFace2, and lung screening computed tomography) are included to evaluate the performance of our method. The proposed MxDRNN improves the baseline performance by a large margin across the different application fields (e.g., accuracy from 46.40% to 76.54% in VGGFace2 test pose set, AUC from 0.7418 to 0.8162 in NLST lung dataset). Additionally, empirical experiments show the MxDRNN is more robust to category-irrelevant attributes (e.g., expression, pose in face images), which may introduce difficulties for image classification and algorithm generalizability. The code is publicly available.","18":"Deep learning has achieved impressive performance across a variety of tasks, including medical image processing. However, recent research has shown that deep neural networks are susceptible to small adversarial perturbations in the image. We study the impact of such adversarial perturbations in medical image processing where the goal is to predict an individual's age based on a 3D MRI brain image. We consider two models: a conventional deep neural network, and a hybrid deep learning model which additionally uses features informed by anatomical context. We find that we can introduce significant errors in predicted age by adding imperceptible noise to an image, can accomplish this even for large batches of images using a single perturbation, and that the hybrid model is much more robust to adversarial perturbations than the conventional deep neural network. Our work highlights limitations of current deep learning techniques in clinical applications, and suggests a path forward.","19":null,"20":"Prediction of individual mobility is crucial in human mobility related applications. Whereas, existing research on individual mobility prediction mainly focuses on next location prediction and short-term dependencies between traveling locations. Long-term location sequence prediction is of great importance for long-time traffic planning and location advertising, and long-term dependencies exist as individual mobility regularity typically occurs daily and weekly. This paper proposes a novel hierarchical temporal attention-based LSTM encoder-decoder model for individual location sequence prediction. The proposed hierarchical attention mechanism captures both long-term and short-term dependencies underlying in individual longitudinal trajectories, and uncovers frequential and periodical mobility patterns in an interpretable manner by incorporating the calendar cycle of individual travel regularities into location prediction. More specifically, the hierarchical attention consists of local temporal attention to identify highly related locations in each day, and global temporal attention to discern important travel regularities over a week. Experiments on individual trajectory datasets with varying degree of traveling uncertainty demonstrate that our method outperforms four baseline methods on three evaluation metrics. In addition, we explore the interpretability of the proposed model in understanding individual daily, and weekly mobility patterns by visualizing the temporal attention weights and frequent traveling patterns associated with locations.","21":"The non-stationary nature of electroencephalography (EEG) signals makes an EEG-based brain-computer interface (BCI) a dynamic system, thus improving its performance is a challenging task. In addition, it is well-known that due to non-stationarity based covariate shifts, the input data distributions of EEG-based BCI systems change during inter- and intra-session transitions, which poses great difficulty for developments of online adaptive data-driven systems. Ensemble learning approaches have been used previously to tackle this challenge. However, passive scheme based implementation leads to poor efficiency while increasing high computational cost. This paper presents a novel integration of covariate shift estimation and unsupervised adaptive ensemble learning (CSE-UAEL) to tackle non-stationarity in motor-imagery (MI) related EEG classification. The proposed method first employs an exponentially weighted moving average model to detect the covariate shifts in the common spatial pattern features extracted from MI related brain responses. Then, a classifier ensemble was created and updated over time to account for changes in streaming input data distribution wherein new classifiers are added to the ensemble in accordance with estimated shifts. Furthermore, using two publicly available BCI-related EEG datasets, the proposed method was extensively compared with the state-of-the-art single-classifier based passive scheme, single-classifier based active scheme and ensemble based passive schemes. The experimental results show that the proposed active scheme based ensemble learning algorithm significantly enhances the BCI performance in MI classifications.","22":"A popular distinction in the human and animal learning literature is between deliberate (or willed) and habitual (or automatic) modes of control. Extensive evidence indicates that, after sufficient learning, living organisms develop behavioural habits that permit them saving computational resources. Furthermore, humans and other animals are able to transfer control from deliberate to habitual modes (and vice versa), trading off efficiently flexibility and parsimony - an ability that is currently unparalleled by artificial control systems. Here, we discuss a computational implementation of habit formation, and the transfer of control from deliberate to habitual modes (and vice versa) within Active Inference: a computational framework that merges aspects of cybernetic theory and of Bayesian inference. To model habit formation, we endow an Active Inference agent with a mechanism to \"cache\" (or memorize) policy probabilities from previous trials, and reuse them to skip - in part or in full - the inferential steps of deliberative processing. We exploit the fact that the relative quality of policies, conditioned upon hidden states, is constant over trials; provided that contingencies and prior preferences do not change. This means the only quantity that can change policy selection is the prior distribution over the initial state - where this prior is based upon the posterior beliefs from previous trials. Thus, an agent that caches the quality (or the probability) of policies can safely reuse cached values to save on cognitive and computational resources - unless contingencies change. Our simulations illustrate the computational benefits, but also the limits, of three caching schemes under Active Inference. They suggest that key aspects of habitual behaviour - such as perseveration - can be explained in terms of caching policy probabilities. Furthermore, they suggest that there may be many kinds (or stages) of habitual behaviour, each associated with a different caching scheme; for example, caching associated or not associated with contextual estimation. These schemes are more or less impervious to contextual and contingency changes.","23":"Despite the state-of-the-art performance for medical image segmentation, deep convolutional neural networks (CNNs) have rarely provided uncertainty estimations regarding their segmentation outputs, e.g., model (epistemic) and image-based (aleatoric) uncertainties. In this work, we analyze these different types of uncertainties for CNN-based 2D and 3D medical image segmentation tasks at both pixel level and structure level. We additionally propose a test-time augmentation-based aleatoric uncertainty to analyze the effect of different transformations of the input image on the segmentation output. Test-time augmentation has been previously used to improve segmentation accuracy, yet not been formulated in a consistent mathematical framework. Hence, we also propose a theoretical formulation of test-time augmentation, where a distribution of the prediction is estimated by Monte Carlo simulation with prior distributions of parameters in an image acquisition model that involves image transformations and noise. We compare and combine our proposed aleatoric uncertainty with model uncertainty. Experiments with segmentation of fetal brains and brain tumors from 2D and 3D Magnetic Resonance Images (MRI) showed that 1) the test-time augmentation-based aleatoric uncertainty provides a better uncertainty estimation than calculating the test-time dropout-based model uncertainty alone and helps to reduce overconfident incorrect predictions, and 2) our test-time augmentation outperforms a single-prediction baseline and dropout-based multiple predictions.","24":"In recent years, analyzing task-based fMRI (tfMRI) data has become an essential tool for understanding brain function and networks. However, due to the sheer size of tfMRI data, its intrinsic complex structure, and lack of ground truth of underlying neural activities, modeling tfMRI data is hard and challenging. Previously proposed data modeling methods including Independent Component Analysis (ICA) and Sparse Dictionary Learning only provided shallow models based on blind source separation under the strong assumption that original fMRI signals could be linearly decomposed into time series components with corresponding spatial maps. Given the Convolutional Neural Network (CNN) successes in learning hierarchical abstractions from low-level data such as tfMRI time series, in this work we propose a novel scalable distributed deep CNN autoencoder model and apply it for fMRI big data analysis. This model aims to both learn the complex hierarchical structures of the tfMRI big data and to leverage the processing power of multiple GPUs in a distributed fashion. To deploy such a model, we have created an enhanced processing pipeline on the top of Apache Spark and Tensorflow, leveraging from a large cluster of GPU nodes over cloud. Experimental results from applying the model on the Human Connectome Project (HCP) data show that the proposed model is efficient and scalable toward tfMRI big data modeling and analytics, thus enabling data-driven extraction of hierarchical neuroscientific information from massive fMRI big data.","25":"Recurrent Neural Networks (RNN) are a type of statistical model designed to handle sequential data. The model reads a sequence one symbol at a time. Each symbol is processed based on information collected from the previous symbols. With existing RNN architectures, each symbol is processed using only information from the previous processing step. To overcome this limitation, we propose a new kind of RNN model that computes a recurrent weighted average (RWA) over every past processing step. Because the RWA can be computed as a running average, the computational overhead scales like that of any other RNN architecture. The approach essentially reformulates the attention mechanism into a stand-alone model. The performance of the RWA model is assessed on the variable copy problem, the adding problem, classification of artificial grammar, classification of sequences by length, and classification of the MNIST images (where the pixels are read sequentially one at a time). On almost every task, the RWA model is found to fit the data significantly faster than a standard LSTM model.","26":"Many unsupervised kernel methods rely on the estimation of kernel covariance operator (kernel CO) or kernel cross-covariance operator (kernel CCO). Both are sensitive to contaminated data, even when bounded positive definite kernels are used. To the best of our knowledge, there are few well-founded robust kernel methods for statistical unsupervised learning. In addition, while the influence function (IF) of an estimator can characterize its robustness, asymptotic properties and standard error, the IF of a standard kernel canonical correlation analysis (standard kernel CCA) has not been derived yet. To fill this gap, we first propose a robust kernel covariance operator (robust kernel CO) and a robust kernel cross-covariance operator (robust kernel CCO) based on a generalized loss function instead of the quadratic loss function. Second, we derive the IF for robust kernel CCO and standard kernel CCA. Using the IF of the standard kernel CCA, we can detect influential observations from two sets of data. Finally, we propose a method based on the robust kernel CO and the robust kernel CCO, called robust kernel CCA, which is less sensitive to noise than the standard kernel CCA. The introduced principles can also be applied to many other kernel methods involving kernel CO or kernel CCO. Our experiments on both synthesized and imaging genetics data demonstrate that the proposed IF of standard kernel CCA can identify outliers. It is also seen that the proposed robust kernel CCA method performs better for ideal and contaminated data than the standard kernel CCA.","27":"Graphical processing units (GPUs) can significantly accelerate spiking neural network (SNN) simulations by exploiting parallelism for independent computations. Both the changes in membrane potential at each time-step, and checking for spiking threshold crossings for each neuron, can be calculated independently. However, because synaptic transmission requires communication between many different neurons, efficient parallel processing may be hindered, either by data transfers between GPU and CPU at each time-step or, alternatively, by running many parallel computations for neurons that do not elicit any spikes. This, in turn, would lower the effective throughput of the simulations. Traditionally, a central processing unit (CPU, host) administers the execution of parallel processes on the GPU (device), such as memory initialization on the device, data transfer between host and device, and starting and synchronizing parallel processes. The parallel computing platform CUDA 5.0 introduced dynamic parallelism, which allows the initiation of new parallel applications within an ongoing parallel kernel. Here, we apply dynamic parallelism for synaptic updating in SNN simulations on a GPU. Our algorithm eliminates the need to start many parallel applications at each time-step, and the associated lags of data transfer between CPU and GPU memories. We report a significant speed-up of SNN simulations, when compared to former accelerated parallelization strategies for SNNs on a GPU.","28":"Rician noise removal for Magnetic Resonance Imaging (MRI) is very important because the MRI has been widely used in various clinical applications and the associated Rician noise deteriorates the image quality and causes errors in interpreting the images. Great efforts have recently been devoted to develop the corresponding noise-removal algorithms, particularly the development based on the newly-established Total Variation (TV) theorem. However, all the TV-based algorithms depend mainly on the gradient information and have been shown to produce the so called \"blocky\" artifact, which also deteriorates the image quality and causes image interpretation errors. In order to avoid producing the artifact, this paper presents a new de-noising model based on sparse representation and dictionary learning. The Split Bregman Iteration strategy is employed to implement the model. Furthermore, an appropriate dictionary is designed by the use of the Kernel Singular Value Decomposition method, resulting in a new Rician noise removal algorithm. Compared with other de-noising algorithms, the presented new algorithm can achieve superior performance, in terms of quantitative measures of the Structural Similarity Index and Peak Signal to Noise Ratio, by a series of experiments using different images in the presence of Rician noise.","29":"Research on Faster R-CNN has recently witnessed the progress in both accuracy and execution efficiency in detecting objects such as faces, hands or pedestrians in photograph or video. However, constrained by the size of its convolution feature map output, it is unable to clearly detect small or tiny objects. Therefore, we presented a fast, deep convolutional neural network based on a modified Faster R-CNN. Multiple strategies, such as fast multi-level combination, context cues, and a new anchor generating method were employed for small object detection in this paper. We demonstrated performance of our algorithm both on the KITTI-ROAD dataset and our own traffic scene lane markings dataset. Experiments demonstrated that our algorithm obtained better accuracy than Faster R-CNN in small object detection.","30":"Total variation (TV) minimization for the sparse-view x-ray computer tomography (CT) reconstruction has been widely explored to reduce radiation dose. However, due to the piecewise constant assumption for the TV model, the reconstructed images often suffer from over-smoothness on the image edges. To mitigate this drawback of TV minimization, we present a Mumford-Shah total variation (MSTV) minimization algorithm in this paper. The presented MSTV model is derived by integrating TV minimization and Mumford-Shah segmentation. Subsequently, a penalized weighted least-squares (PWLS) scheme with MSTV is developed for the sparse-view CT reconstruction. For simplicity, the proposed algorithm is named as 'PWLS-MSTV.' To evaluate the performance of the present PWLS-MSTV algorithm, both qualitative and quantitative studies were conducted by using a digital XCAT phantom and a physical phantom. Experimental results show that the present PWLS-MSTV algorithm has noticeable gains over the existing algorithms in terms of noise reduction, contrast-to-ratio measure and edge-preservation.","31":"Cervical auscultation is a method for assessing swallowing performance. However, its ability to serve as a classification tool for a practical clinical assessment method is not fully understood. In this study, we utilized neural network classification methods in the form of Deep Belief networks in order to classify swallows. We specifically utilized swallows that did not result in clinically significant aspiration and classified them on whether they originated from healthy subjects or unhealthy patients. Dual-axis swallowing vibrations from 1946 discrete swallows were recorded from 55 healthy and 53 unhealthy subjects. The Fourier transforms of both signals were used as inputs to the networks of various sizes. We found that single and multi-layer Deep Belief networks perform nearly identically when analyzing only a single vibration signal. However, multi-layered Deep Belief networks demonstrated approximately a 5% to 10% greater accuracy and sensitivity when both signals were analyzed concurrently, indicating that higher-order relationships between these vibrations are important for classification and assessment.","32":"The first year of life is the most dynamic and perhaps the most critical phase of postnatal brain development. The ability to accurately measure structure changes is critical in early brain development study, which highly relies on the performances of image segmentation and registration techniques. However, either infant image segmentation or registration, if deployed independently, encounters much more challenges than segmentation\/registration of adult brains due to dynamic appearance change with rapid brain development. In fact, image segmentation and registration of infant images can assists each other to overcome the above challenges by using the growth trajectories (i.e., temporal correspondences) learned from a large set of training subjects with complete longitudinal data. Specifically, a one-year-old image with ground-truth tissue segmentation can be first set as the reference domain. Then, to register the infant image of a new subject at earlier age, we can estimate its tissue probability maps, i.e., with sparse patch-based multi-atlas label fusion technique, where only the training images at the respective age are considered as atlases since they have similar image appearance. Next, these probability maps can be fused as a good initialization to guide the level set segmentation. Thus, image registration between the new infant image and the reference image is free of difficulty of appearance changes, by establishing correspondences upon the reasonably segmented images. Importantly, the segmentation of new infant image can be further enhanced by propagating the much more reliable label fusion heuristics at the reference domain to the corresponding location of the new infant image via the learned growth trajectories, which brings image segmentation and registration to assist each other. It is worth noting that our joint segmentation and registration framework is also flexible to handle the registration of any two infant images even with significant age gap in the first year of life, by linking their joint segmentation and registration through the reference domain. Thus, our proposed joint segmentation and registration method is scalable to various registration tasks in early brain development studies. Promising segmentation and registration results have been achieved for infant brain MR images aged from 2-week-old to 1-year-old, indicating the applicability of our method in early brain development study.","33":"Class imbalance presents a major hurdle in the application of classification methods. A commonly taken approach is to learn ensembles of classifiers using rebalanced data. Examples include bootstrap averaging (bagging) combined with either undersampling or oversampling of the minority class examples. However, rebalancing methods entail asymmetric changes to the examples of different classes, which in turn can introduce their own biases. Furthermore, these methods often require specifying the performance measure of interest a priori, i.e., before learning. An alternative is to employ the threshold moving technique, which applies a threshold to the continuous output of a model, offering the possibility to adapt to a performance measure a posteriori, i.e., a plug-in method. Surprisingly, little attention has been paid to this combination of a bagging ensemble and threshold-moving. In this paper, we study this combination and demonstrate its competitiveness. Contrary to the other resampling methods, we preserve the natural class distribution of the data resulting in well-calibrated posterior probabilities. Additionally, we extend the proposed method to handle multiclass data. We validated our method on binary and multiclass benchmark data sets by using both, decision trees and neural networks as base classifiers. We perform analyses that provide insights into the proposed method.","34":"Positron emission tomography (PET) is an essential technique in many clinical applications such as tumor detection and brain disorder diagnosis. In order to obtain high-quality PET images, a standard-dose radioactive tracer is needed, which inevitably causes the risk of radiation exposure damage. For reducing the patient's exposure to radiation and maintaining the high quality of PET images, in this paper, we propose a deep learning architecture to estimate the high-quality standard-dose PET (SPET) image from the combination of the low-quality low-dose PET (LPET) image and the accompanying T1-weighted acquisition from magnetic resonance imaging (MRI). Specifically, we adapt the convolutional neural network (CNN) to account for the two channel inputs of LPET and T1, and directly learn the end-to-end mapping between the inputs and the SPET output. Then, we integrate multiple CNN modules following the auto-context strategy, such that the tentatively estimated SPET of an early CNN can be iteratively refined by subsequent CNNs. Validations on real human brain PET\/MRI data show that our proposed method can provide competitive estimation quality of the PET images, compared to the state-of-the-art methods. Meanwhile, our method is highly efficient to test on a new subject, e.g., spending ~2 seconds for estimating an entire SPET image in contrast to ~16 minutes by the state-of-the-art method. The results above demonstrate the potential of our method in real clinical applications.","35":"Stroke is the leading cause of long-term disability and the second leading cause of mortality in the world, and exerts an enormous burden on the public health. Computed Tomography (CT) remains one of the most widely used imaging modality for acute stroke diagnosis. However when coupled with CT perfusion, the excessive radiation exposure in repetitive imaging to assess treatment response and prognosis has raised significant public concerns regarding its potential hazards to both short- and long-term health outcomes. Tensor total variation has been proposed to reduce the necessary radiation dose in CT perfusion without comprising the image quality by fusing the information of the local anatomical structure with the temporal blood flow model. However the local search in the TTV framework fails to leverage the non-local information in the spatio-temporal data. In this paper, we propose TENDER, an efficient framework of non-local tensor deconvolution to maintain the accuracy of the hemodynamic parameters and the diagnostic reliability in low radiation dose CT perfusion. The tensor total variation is extended using non-local spatio-temporal cubics for regularization, and an efficient algorithm is proposed to reduce the time complexity with speedy similarity computation. Evaluations on clinical data of patients subjects with cerebrovascular disease and normal subjects demonstrate the advantage of non-local tensor deconvolution for reducing radiation dose in CT perfusion.","36":"Epithelial (EP) and stromal (ST) are two types of tissues in histological images. Automated segmentation or classification of EP and ST tissues is important when developing computerized system for analyzing the tumor microenvironment. In this paper, a Deep Convolutional Neural Networks (DCNN) based feature learning is presented to automatically segment or classify EP and ST regions from digitized tumor tissue microarrays (TMAs). Current approaches are based on handcraft feature representation, such as color, texture, and Local Binary Patterns (LBP) in classifying two regions. Compared to handcrafted feature based approaches, which involve task dependent representation, DCNN is an end-to-end feature extractor that may be directly learned from the raw pixel intensity value of EP and ST tissues in a data driven fashion. These high-level features contribute to the construction of a supervised classifier for discriminating the two types of tissues. In this work we compare DCNN based models with three handcraft feature extraction based approaches on two different datasets which consist of 157 Hematoxylin and Eosin (H&amp;E) stained images of breast cancer and 1376 immunohistological (IHC) stained images of colorectal cancer, respectively. The DCNN based feature learning approach was shown to have a F1 classification score of 85%, 89%, and 100%, accuracy (ACC) of 84%, 88%, and 100%, and Matthews Correlation Coefficient (MCC) of 86%, 77%, and 100% on two H&amp;E stained (NKI and VGH) and IHC stained data, respectively. Our DNN based approach was shown to outperform three handcraft feature extraction based approaches in terms of the classification of EP and ST regions.","37":"Automatic labeling of the hippocampus in brain MR images is highly demanded, as it has played an important role in imaging-based brain studies. However, accurate labeling of the hippocampus is still challenging, partially due to the ambiguous intensity boundary between the hippocampus and surrounding anatomies. In this paper, we propose a concatenated set of spatially-localized random forests for multi-atlas-based hippocampus labeling of adult\/infant brain MR images. The contribution in our work is two-fold. First, each forest classifier is trained to label just a specific sub-region of the hippocampus, thus enhancing the labeling accuracy. Second, a novel forest selection strategy is proposed, such that each voxel in the test image can automatically select a set of optimal forests, and then dynamically fuses their respective outputs for determining the final label. Furthermore, we enhance the spatially-localized random forests with the aid of the auto-context strategy. In this way, our proposed learning framework can gradually refine the tentative labeling result for better performance. Experiments show that, regarding the large datasets of both adult and infant brain MR images, our method owns satisfactory scalability by segmenting the hippocampus accurately and efficiently.","38":"Content-based medical image retrieval (CBMIR) is an active research area for disease diagnosis and treatment but it can be problematic given the small visual variations between anatomical structures. We propose a retrieval method based on a bag-of-visual-words (BoVW) to identify discriminative characteristics between different medical images with Pruned Dictionary based on Latent Semantic Topic description. We refer to this as the PD-LST retrieval. Our method has two main components. First, we calculate a topic-word significance value for each visual word given a certain latent topic to evaluate how the word is connected to this latent topic. The latent topics are learnt, based on the relationship between the images and words, and are employed to bridge the gap between low-level visual features and high-level semantics. These latent topics describe the images and words semantically and can thus facilitate more meaningful comparisons between the words. Second, we compute an overall-word significance value to evaluate the significance of a visual word within the entire dictionary. We designed an iterative ranking method to measure overall-word significance by considering the relationship between all latent topics and words. The words with higher values are considered meaningful with more significant discriminative power in differentiating medical images. We evaluated our method on two public medical imaging datasets and it showed improved retrieval accuracy and efficiency.","39":"Cerebral perfusion x-ray computed tomography (PCT) is an important functional imaging modality for evaluating cerebrovascular diseases and has been widely used in clinics over the past decades. However, due to the protocol of PCT imaging with repeated dynamic sequential scans, the associative radiation dose unavoidably increases as compared with that used in conventional CT examinations. Minimizing the radiation exposure in PCT examination is a major task in the CT field. In this paper, considering the rich similarity redundancy information among enhanced sequential PCT images, we propose a low-dose PCT image restoration model by incorporating the low-rank and sparse matrix characteristic of sequential PCT images. Specifically, the sequential PCT images were first stacked into a matrix (i.e., low-rank matrix), and then a non-convex spectral norm\/regularization and a spatio-temporal total variation norm\/regularization were then built on the low-rank matrix to describe the low rank and sparsity of the sequential PCT images, respectively. Subsequently, an improved split Bregman method was adopted to minimize the associative objective function with a reasonable convergence rate. Both qualitative and quantitative studies were conducted using a digital phantom and clinical cerebral PCT datasets to evaluate the present method. Experimental results show that the presented method can achieve images with several noticeable advantages over the existing methods in terms of noise reduction and universal quality index. More importantly, the present method can produce more accurate kinetic enhanced details and diagnostic hemodynamic parameter maps.","40":"Noise artifacts in magnetic resonance (MR) images increase the complexity of image processing workflows and decrease the reliability of inferences drawn from the images. It is thus often desirable to remove such artifacts beforehand for more robust and effective quantitative analysis. It is important to preserve the integrity of relevant image information while removing noise in MR images. A variety of approaches have been developed for this purpose, and the non-local means (NLM) filter has been shown to be able to achieve state-of-the-art denoising performance. For effective denoising, NLM relies heavily on the existence of repeating structural patterns, which however might not always be present within a single image. This is especially true when one considers the fact that the human brain is complex and contains a lot of unique structures. In this paper we propose to leverage the repeating structures from multiple images to collaboratively denoise an image. The underlying assumption is that it is more likely to find repeating structures from multiple scans than from a single scan. Specifically, to denoise a target image, multiple images, which may be acquired from different subjects, are spatially aligned to the target image, and an NLM-like block matching is performed on these aligned images with the target image as the reference. This will significantly increase the number of matching structures and thus boost the denoising performance. Experiments on both synthetic and real data show that the proposed approach, collaborative non-local means (CNLM), outperforms the classic NLM and yields results with markedly improved structural details.","41":"Recognition of human actions from digital video is a challenging task due to complex interfering factors in uncontrolled realistic environments. In this paper, we propose a learning framework using static, dynamic and sequential mixed features to solve three fundamental problems: spatial domain variation, temporal domain polytrope, and intra- and inter-class diversities. Utilizing a cognitive-based data reduction method and a hybrid \"network upon networks\" architecture, we extract human action representations which are robust against spatial and temporal interferences and adaptive to variations in both action speed and duration. We evaluated our method on the UCF101 and other three challenging datasets. Our results demonstrated a superior performance of the proposed algorithm in human action recognition.","42":"The uniformly pseudo-projection-anti-monotone (UPPAM) neural network model, which can be considered as the unified continuous-time neural networks (CNNs), includes almost all of the known CNNs individuals. Recently, studies on the critical dynamics behaviors of CNNs have drawn special attentions due to its importance in both theory and applications. In this paper, we will present the analysis of the UPPAM network under the general critical conditions. It is shown that the UPPAM network possesses the global convergence and asymptotical stability under the general critical conditions if the network satisfies one quasi-symmetric requirement on the connective matrices, which is easy to be verified and applied. The general critical dynamics have rarely been studied before, and this work is an attempt to gain an meaningful assurance of general critical convergence and stability of CNNs. Since UPPAM network is the unified model for CNNs, the results obtained here can generalize and extend the existing critical conclusions for CNNs individuals, let alone those non-critical cases. Moreover, the easily verified conditions for general critical convergence and stability can further promote the applications of CNNs.","43":"In1 recent years, there has been a great interest in prostate segmentation, which is a important and challenging task for CT image guided radiotherapy. In this paper, a learning-based segmentation method via joint transductive feature selection and transductive regression is presented, which incorporates the physician's simple manual specification (only taking a few seconds), to aid accurate segmentation, especially for the case with large irregular prostate motion. More specifically, for the current treatment image, experienced physician is first allowed to manually assign the labels for a small subset of prostate and non-prostate voxels, especially in the first and last slices of the prostate regions. Then, the proposed method follows the two step: in prostate-likelihood estimation step, two novel algorithms: tLasso and wLapRLS, will be sequentially employed for transductive feature selection and transductive regression, respectively, aiming to generate the prostate-likelihood map. In multi-atlases based label fusion step, the final segmentation result will be obtained according to the corresponding prostate-likelihood map and the previous images of the same patient. The proposed method has been substantially evaluated on a real prostate CT dataset including 24 patients with 330 CT images, and compared with several state-of-the-art methods. Experimental results show that the proposed method outperforms the state-of-the-arts in terms of higher Dice ratio, higher true positive fraction, and lower centroid distances. Also, the results demonstrate that simple manual specification can help improve the segmentation performance, which is clinically feasible in real practice.","44":"Most seizure forecasting employs statistical learning techniques that lack a representation of the network interactions that give rise to seizures. We present an epilepsy network emulator (ENE) that uses a network of interconnected phase-locked loops (PLLs) to model synchronous, circuit-level oscillations between electrocorticography (ECoG) electrodes. Using ECoG data from a canine-epilepsy model (Davis et al. 2011) and a physiological entropy measure (approximate entropy or ApEn, Pincus 1995), we demonstrate the entropy of the emulator phases increases dramatically during ictal periods across all ECoG recording sites and across all animals in the sample. Further, this increase precedes the observable voltage spikes that characterize seizure activity in the ECoG data. These results suggest that the ENE is sensitive to phase-domain information in the neural circuits measured by ECoG and that an increase in the entropy of this measure coincides with increasing likelihood of seizure activity. Understanding this unpredictable phase-domain electrical activity present in ECoG recordings may provide a target for seizure detection and feedback control.","45":null,"46":"The perception of 3D structure in dynamic sequences is believed to be subserved primarily through the use of motion cues. However, real-world sequences contain many figural shape cues besides the dynamic ones. We hypothesize that if figural cues are perceptually significant during sequence analysis, then inconsistencies in these cues over time would lead to percepts of non-rigidity in sequences showing physically rigid objects in motion. We develop an experimental paradigm to test this hypothesis and present results with two patients with impairments in motion perception due to focal neurological damage, as well as two control subjects. Consistent with our hypothesis, the data suggest that figural cues strongly influence the perception of structure in motion sequences, even to the extent of inducing non-rigid percepts in sequences where motion information alone would yield rigid structures. Beyond helping to probe the issue of shape perception, our experimental paradigm might also serve as a possible perceptual assessment tool in a clinical setting.","47":"Laser interstitial thermal therapy (LITT) is a new therapeutic strategy being explored in prostate cancer (CaP), which involves focal ablation of organlocalized tumor via an interstitial laser fiber. While little is known about treatment-related changes following LITT, studying post-LITT changes via imaging is extremely significant for enabling early image-guided intervention and follow-up. In this work, we present the first attempt at examining focal treatment-related changes on a per-voxel basis via quantitative comparison of MRI features pre- and post-LITT, and hence identifying computerized MRI features that are highly sensitive as well as specific to post-LITT changes within the ablation zone in the prostate. A retrospective cohort of 5 patient datasets comprising both pre- and post-LITT T2-weighted (T2w) and diffusion-weighted (DWI) acquisitions was considered, where DWI MRI yielded an Apparent Diffusion Co-efficient (ADC) map. Our scheme involved (1) inter-protocol registration of T2w and ADC MRI, as well as inter-acquisition registration of pre- and post-LITT MRI, (2) quantitation of MRI parameters by correcting for intensity drift in order to examine tissuespecific response, and (3) quantification of the information captured by T2w MRI and ADC maps via texture and intensity features. Correction of parameter drift resulted in visually discernible improvements in highlighting tissue-specific response in different MRI features. Quantitative, voxel-wise comparison of the changes in different MRI features indicated that steerable and non-steerable gradient texture features, rather than the original T2w intensity and ADC values, were highly sensitive as well as specific in identifying changes within the ablation zone pre- and post-LITT. The highest ranked texture feature yielded a normalized percentage change of 186% within the ablation zone and 43% in a spatially distinct normal region, relative to its pre-LITT value. By comparison, both the original T2w intensity and ADC value demonstrated a markedly less sensitive and specific response to changes within the ablation zone. Qualitative as well as quantitative evaluation of co-occurrence texture features indicated the presence of LITT-related effects such as edema adjacent to the ablation zone, which were indiscernible on the original T2w and ADC images. Our preliminary results thus indicate great potential for non-invasive computerized MRI imaging features for determining focal treatment related changes, informing image-guided interventions, as well as predicting long- and short-term patient outcome.","48":"External beam radiation treatment (EBRT) is a popular method for treating prostate cancer (CaP) involving destroying tumor cells with ionizing radiation. Following EBRT, biochemical failure has been linked with disease recurrence. However, there is a need for methods for evaluating early treatment related changes to allow for an early intervention in case of incomplete disease response. One method for looking at treatment evaluation is to detect changes in MRI markers on a voxel-by-voxel basis following treatment. Changes in MRI markers may be correlated with disease recurrence and complete or partial response. In order to facilitate voxel-by-voxel imaging related treatment changes, and also to evaluate morphologic changes in the gland post treatment, the pre- and post-radiated MRI must first be brought into spatial alignment via image registration. However, EBRT induces changes in the prostate volume and distortion to the internal anatomy of the prostate following radiation treatment. The internal substructures of the prostate, the central gland (CG) and peripheral zone (PZ), may respond to radiation differently, and their resulting shapes may change drastically. Biomechanical models of the prostate that have been previously proposed tend to focus on how external forces affect the surface of the prostate (not the internals), and assume that the prostate is a volume-preserving entity. In this work we present DoCD, a biomechanical model for automatically registering pre-, post-EBRT MRI with the aim of expressly modeling the (1) changes in volume, and (2) changes to the CG and PZ. DoCD was applied to a cohort of 30 patients and achieved a root mean square error of 2.994 mm, which was statistically significantly better a traditional biomechanical model which did not consider changes to the internal anatomy of the prostate (mean of 5.071 mm).","49":"In this work, we present a novel learning based fiducial driven registration (LeFiR) scheme which utilizes a point matching technique to identify the optimal configuration of landmarks to better recover deformation between a target and a moving image. Moreover, we employ the LeFiR scheme to model the localized nature of deformation introduced by a new treatment modality - laser induced interstitial thermal therapy (LITT) for treating neurological disorders. Magnetic resonance (MR) guided LITT has recently emerged as a minimally invasive alternative to craniotomy for local treatment of brain diseases (such as glioblastoma multiforme (GBM), epilepsy). However, LITT is currently only practised as an investigational procedure world-wide due to lack of data on longer term patient outcome following LITT. There is thus a need to quantitatively evaluate treatment related changes between post- and pre-LITT in terms of MR imaging markers. In order to validate LeFiR, we tested the scheme on a synthetic brain dataset (SBD) and in two real clinical scenarios for treating GBM and epilepsy with LITT. Four experiments under different deformation profiles simulating localized ablation effects of LITT on MRI were conducted on 286 pairs of SBD images. The training landmark configurations were obtained through 2000 iterations of registration where the points with consistently best registration performance were selected. The estimated landmarks greatly improved the quality metrics compared to a uniform grid (UniG) placement scheme, a speeded-up robust features (SURF) based method, and a scale-invariant feature transform (SIFT) based method as well as a generic free-form deformation (FFD) approach. The LeFiR method achieved average 90% improvement in recovering the local deformation compared to 82% for the uniform grid placement, 62% for the SURF based approach, and 16% for the generic FFD approach. On the real GBM and epilepsy data, the quantitative results showed that LeFiR outperformed UniG by 28% improvement in average.","50":"Finding mucosal abnormalities (e.g., erythema, blood, ulcer, erosion, and polyp) is one of the most essential tasks during endoscopy video review. Since these abnormalities typically appear in a small number of frames (around 5% of the total frame number), automated detection of frames with an abnormality can save physician's time significantly. In this paper, we propose a new multi-texture analysis method that effectively discerns images showing mucosal abnormalities from the ones without any abnormality since most abnormalities in endoscopy images have textures that are clearly distinguishable from normal textures using an advanced image texture analysis method. The method uses a \"texton histogram\" of an image block as features. The histogram captures the distribution of different \"textons\" representing various textures in an endoscopy image. The textons are representative response vectors of an application of a combination of Leung and Malik (LM) filter bank (i.e., a set of image filters) and a set of Local Binary Patterns on the image. Our experimental results indicate that the proposed method achieves 92% recall and 91.8% specificity on wireless capsule endoscopy (WCE) images and 91% recall and 90.8% specificity on colonoscopy images.","51":"Recent advances in microsystems technology led to a miniaturization of cuff-electrodes, which suggests these electrodes not just for long-term neuronal recordings in mammalians, but also in medium-sized insects. In this study we investigated the possibilities offered by cuff-electrodes for neuroethology using insects as a model organism. The implantation in the neck of a tropical bushcricket resulted in high quality extracellular nerve recordings of different units responding to various acoustic, vibratory, optical and mechanical stimuli. In addition, multi-unit nerve activity related to leg movements was recorded in insects walking on a trackball. A drawback of bi-polar nerve recordings obtained during tethered flight was overlay of nerve activity with large amplitude muscle potentials. Interestingly, cuff-electrode recordings were robust to withstand walking and flight activity so that good quality nerve recordings were possible even three days after electrode implantation. Recording multi-unit nerve activity in intact insects required an elaborate spike sorting algorithm in order to discriminate neuronal units responding to external stimuli from background activity. In future, a combination of miniaturized cuff-electrodes and light-weight amplifiers equipped with a wireless transmitter will allow the investigation of neuronal processes underlying natural behavior in freely moving insects. By this means cuff-electrodes may contribute to the development of realistic neuronal models simulating neuronal processes underlying natural insect behavior, such like mate choice and predator avoidance.","52":"In the present paper, we use data mining methods to address two challenges in the sharing and integration of data from electrophysiological (ERP) studies of human brain function. The first challenge, ERP metric matching, is to identify correspondences among distinct summary features (\"metrics\") in ERP datasets from different research labs. The second challenge, ERP pattern matching, is to align the ERP patterns or \"components\" in these datasets. We address both challenges within a unified framework. The utility of this framework is illustrated in a series of experiments using ERP datasets that are designed to simulate heterogeneities from three sources: (a) different groups of subjects with distinct simulated patterns of brain activity, (b) different measurement methods, i.e, alternative spatial and temporal metrics, and (c) different patterns, reflecting the use of alternative pattern analysis techniques. Unlike real ERP data, the simulated data are derived from known source patterns, providing a gold standard for evaluation of the proposed matching methods. Using this approach, we demonstrate that the proposed method outperforms well-known existing methods, because it utilizes cluster-based structure and thus achieves finer-grained representation of the multidimensional (spatial and temporal) attributes of ERP data.","53":"To construct biologically interpretable gene sets for muscular dystrophy (MD) sub-type classification, we propose a novel computational scheme to integrate protein-protein interaction (PPI) network, functional gene set information, and mRNA profiling data. The workflow of the proposed scheme includes the following three major steps: firstly, we apply an affinity propagation clustering (APC) approach to identify gene sub-networks associated with each MD sub-type, in which a new distance metric is proposed for APC to combine PPI network information and gene-gene co-expression relationship; secondly, we further incorporate functional gene set knowledge, which complements the physical PPI information, into our scheme for biomarker identification; finally, based on the constructed sub-networks and gene set features, we apply multi-class support vector machines (MSVMs) for MD sub-type classification, with which to highlight the biomarkers contributing to sub-type prediction. The experimental results show that our scheme can help identify sub-networks and gene sets that are more relevant to MD than those constructed by other conventional approaches. Moreover, our integrative strategy improves the prediction accuracy substantially, especially for those 'hard-to-classify' sub-types.","54":"Chronic pain has profound effects on activity. Previous reports indicate chronic inflammatory conditions result in reduced activity which normalizes upon pain treatment. However, there is little systematic investigation of this process. Rheumatoid arthritis is an autoimmune disorder that causes significant joint pain. The K\/BxN serum transfer mouse has been characterized as a model for rheumatoid arthritis and chronic pain. We investigated the activity of mice following K\/BxN serum transfer vs. control serum and observed the activity changes following delivery of an NSAID, ketorolac. Previous studies have used running wheels and laser beams to monitor activity; we chose to validate a model using cost-effective infrared sensors on individual cages. Each mouse had its baseline activity obtained, which showed significant variation between individual C57Bl\/6 mice. Arthritic mice had significantly decreased activity for only the first 11 nights. Conversely, previous work has shown that these animals display tactile allodynia that persists for at least 45 days. Mice were treated with ketorolac in their drinking water (10mg\/kg, 15mg\/kg, or 20mg\/kg) for nights 6-8. The two highest doses showed significant normalization of activity levels. Four nights after ketorolac was stopped, treated animals were still significantly more active than control. The reversal of the reduced activity provides support that the depression relates to the arthritic pain state of the animal. These results indicate the efficacy of activity monitoring to better investigate behavior in persistent pain states. However, insofar as depressed activity reflects pain and disability, the present work raises questions as to the relevance of the tactile thresholds in defining behaviorally relevant pain states.","55":"Although nonnegative matrix factorization (NMF) favors a sparse and part-based representation of nonnegative data, there is no guarantee for this behavior. Several authors proposed NMF methods which enforce sparseness by constraining or penalizing the [Formula: see text] of the factor matrices. On the other hand, little work has been done using a more natural sparseness measure, the [Formula: see text]. In this paper, we propose a framework for approximate NMF which constrains the [Formula: see text] of the basis matrix, or the coefficient matrix, respectively. For this purpose, techniques for unconstrained NMF can be easily incorporated, such as multiplicative update rules, or the alternating nonnegative least-squares scheme. In experiments we demonstrate the benefits of our methods, which compare to, or outperform existing approaches.","56":"Significant progress has been made within the last decade in motor cortical decoding that predicts movement behaviors from population neuronal activity in the motor cortex. A majority of these decoding methods have focused on estimating a subject's hand trajectory in a continuous movement. We recently proposed a time identification decoding approach and showed that if a stereotyped movement is well represented by a sequence of targets (or landmarks), then the main structure of the movement can be reconstructed by detecting the reaching times at those targets. Both trajectory decoding and landmark-time decoding have their particular advantages, whereas a coupling of these two different strategies has not been examined. In this article we propose a synergy that comes from combining these two approaches for a stereotyped movement under a linear state-space framework. We develop a new decoding procedure based on a forward-backward propagation where the target is used in the initial stage in the backward step. Experimental results show that the new method significantly improves decoding accuracy over the non-target-included models. Furthermore, the coupling based on the new target-included method effectively combines the time decoding and trajectory decoding and further improves the decoding accuracy.","57":"A new technique to extract and evaluate physical activity patterns from image sequences captured by a wearable camera is presented in this paper. Unlike standard activity recognition schemes, the video data captured by our device do not include the wearer him\/herself. The physical activity of the wearer, such as walking or exercising, is analyzed indirectly through the camera motion extracted from the acquired video frames. Two key tasks, pixel correspondence identification and motion feature extraction, are studied to recognize activity patterns. We utilize a multiscale approach to identify pixel correspondences. When compared with the existing methods such as the Good Features detector and the Speed-up Robust Feature (SURF) detector, our technique is more accurate and computationally efficient. Once the pixel correspondences are determined which define representative motion vectors, we build a set of activity pattern features based on motion statistics in each frame. Finally, the physical activity of the person wearing a camera is determined according to the global motion distribution in the video. Our algorithms are tested using different machine learning techniques such as the K-Nearest Neighbor (KNN), Naive Bayesian and Support Vector Machine (SVM). The results show that many types of physical activities can be recognized from field acquired real-world video. Our results also indicate that, with a design of specific motion features in the input vectors, different classifiers can be used successfully with similar performances.","58":"","59":"We introduce a model for the computation of structure-from-motion based on the physiology of visual cortical areas MT and MST. The model assumes that the perception of depth from motion is related to the firing of a subset of MT neurons tuned to both velocity and disparity. The model's MT neurons are connected to each other laterally to form modulatory receptive-field surrounds that are gated by feedback connections from area MST. This allows the building up of a depth map from motion in area MT, even in absence of disparity in the input. Depth maps from motion and from stereo are combined by a weighted average at a final stage. The model's predictions for the interaction between motion and stereo cues agree with previous psychophysical data, both when the cues are consistent with each other or when they are contradictory. In particular, the model shows nonlinearities as a result of early interactions between motion and stereo before their depth maps are averaged. The two cues interact in a way that represents an alternative to the \"modified weak fusion\" model of depth-cue combination.","60":"","61":"Network plasticity arises in large part due to the effects of exogenous neuromodulators. We investigate the neuromodulatory effects on short-term synaptic dynamics. The synapse from the lateral pyloric (LP) to the pyloric dilator (PD) neuron in the pyloric network of the crab C. borealis has both spike-mediated and non-spike-mediated (graded) components. Previous studies have shown that the graded component of this synapse exhibits short-term depression. Recent results from our lab indicate that in the presence of neuromodulatory peptide proctolin, low-amplitude presynaptic stimuli switch the short-term dynamics of this graded component from depression to facilitation. In this study, we show that this facilitation is correlated with the activation of a presynaptic inward current that is blocked by Mn(2+) suggesting that it is a slowly-accumulating Ca(2+) current. We modify a mechanistic model of synaptic release by assuming that the low-voltage-activating Ca(2+) current in our system is composed of two currents with fast (I(CaF)) and slow (I(CaS)) kinetics. We show that if proctolin adjusts the activation rate of I(CaS), this leads to accumulation of local intracellular Ca(2+) in response to multiple presynaptic voltage stimuli which, in turn, results in synaptic facilitation. Additionally, we assume that proctolin increases the maximal conductances of Ca(2+) currents in the model, consistent with the increased synaptic release found in the experiments. We find that these two presynaptic actions of proctolin in the model are sufficient to describe its actions on the short-term dynamics of the LP to PD synapse.","62":"Variability of the neuronal spike pattern is usually thought of in terms of the information that the different interspike intervals might be encoding. However, the very presence of the variability can have other kinds of functional significance. Here we consider the example of the B15\/B16-ARC neuromuscular system of Aplysia, a model system for the study of neuromuscular modulation and control. We show that variability of motor neuron spike timing at the input to the system penetrates throughout the system, affecting all downstream variables including modulator release, modulator concentrations, modulatory actions, and the contraction of the muscle. Furthermore, not only does the variability penetrate through the system, but it is actually instrumental in maintaining its modulation and contractions at a robust, physiological level.","63":"We implemented an experimentally observed orthogonal arrangement of theta and gamma generation circuitry in septotemporal and lamellar dimensions is a two-dimensional model of hippocampus. The model includes three types of cells: pyramidal, basket, and oriens lacunosum-moleculare (OLM) neurons. In this reduced model, application of continuous electric fields allowed us to switch between theta, gamma and mixed theta-gamma regimes without additional pharmacological manipulation. Electric field effects on individual neurons were modeled based on experimental data. Network simulation results predict a flexible experimental technique, which would employ adaptive subthreshold electric fields to continuously modulate neuronal ensemble activity, and can be used for testing cognitive correlates of oscillatory rhythms as well as for suppressing epileptiform activity.","64":"The tail-withdrawal circuit of Aplysia provides a useful model system for investigating synaptic dynamics. Sensory neurons within the circuit manifest several forms of synaptic plasticity. Here, we developed a model of the circuit and investigated the ways in which depression (DEP) and potentiation (POT) contributed to information processing. DEP limited the amount of motor neuron activity that could be elicited by the monosynaptic pathway alone. POT within the monosynaptic pathway did not compensate for DEP. There was, however, a synergistic interaction between POT and the polysynaptic pathway. This synergism extended the dynamic range of the network, and the interplay between DEP and POT made the circuit responded preferentially to long-duration, low-frequency inputs.","65":"It has been unclear whether optimal experimental design accounts of data selection may offer insight into evidence acquisition tasks in which the learner's beliefs change greatly during the course of learning. Data from Rehder and Hoffman's eye movement version of Shepard, Horland and Jenkins' classic concept learning task provide an opportunity to address these issues. We introduce a principled probabilistic concept-learning model that describes the development of subjects' beliefs on that task. We use that learning model, together with a sampling function inspired by theory of optimal experimental design, to predict subjects' eye movements on the active learning version of that task. Results show that the same rational sampling function can predict eye movements early in learning, when uncertainty is high, as well as late in learning when the learner is certain of the true category.","66":"Texture boundary detection (or segmentation) is an important capability in human vision. Usually, texture segmentation is viewed as a 2D problem, as the definition of the problem itself assumes a 2D substrate. However, an interesting hypothesis emerges when we ask a question regarding the nature of textures: What are textures, and why did the ability to discriminate texture evolve or develop? A possible answer to this question is that textures naturally define physically distinct (i.e., occluded) surfaces. Hence, we can hypothesize that 2D texture segmentation may be an outgrowth of the ability to discriminate surfaces in 3D. In this paper, we conducted computational experiments with artificial neural networks to investigate the relative difficulty of learning to segment textures defined on flat 2D surfaces vs. those in 3D configurations where the boundaries are defined by occluding surfaces and their change over time due to the observer's motion. It turns out that learning is faster and more accurate in 3D, very much in line with our expectation. Furthermore, our results showed that the neural network's learned ability to segment texture in 3D transfers well into 2D texture segmentation, bolstering our initial hypothesis, and providing insights on the possible developmental origin of 2D texture segmentation function in human vision.","67":"When modulators of neuromuscular function alter the motor neuron spike patterns that elicit muscle contractions, it is predicted that they will also retune correspondingly the connecting processes of the neuromuscular transform. Here we confirm this prediction by analyzing data from the cardiac neuromuscular system of the blue crab. We apply a method that decodes the contraction response to the spike pattern in terms of three elementary building-block functions that completely characterize the neuromuscular transform. This method allows us to dissociate modulator-induced changes in the neuromuscular transform from changes in the spike pattern in the normally operating, essentially unperturbed neuromuscular system.","68":"Introducing theta-modulated input into a minimal model of the CA3 region of the hippocampus has significant effects on gamma oscillations. In the absence of theta-modulated input, the gamma oscillations are robust across a range of parameters. Introducing theta-modulated input weakens the gamma oscillations to a power more consistent with power spectra acquired from laboratory animals. With these changes, simulations of the hippocampal model are able to reproduce hippocampal power spectra measured in awake mice.","69":"Resonance tuning in a model of rhythmic movement is compared when the central pattern generator (CPG) consists of two endogenously bursting or two tonically spiking neurons that are connected with reciprocally inhibitory synapses. The CPG receives inhibitory and\/or excitatory position feedback from a linear, one-degree-of-freedom mechanical subsystem. As with previously published results [5, 15], resonance tuning is limited to frequencies that are greater than the intrinsic CPG frequency with endogenously bursting neurons. In contrast, with tonically spiking neurons, the resonance tuning range is expanded to frequencies that are below the intrinsic CPG frequency.","70":"We derive a mathematical theory to explain the subthreshold resonance response of a neuron to synaptic input. The theory shows how a neuron combines information from its intrinsic resonant properties with those of the synapse to determine the neuron's generalized resonance response. Our results show that the maximal response of a postsynaptic neuron can lie between the preferred intrinsic frequency of the neuron and the synaptic resonance frequency. We compare our theoretical results to parallel findings on experiments of the crab pyloric central pattern generator.","71":"Independent component analysis (ICA) of functional magnetic resonance imaging (fMRI) data is commonly carried out under the assumption that each source may be represented as a spatially fixed pattern of activation, which leads to the instantaneous mixing model. To allow modeling patterns of spatio-temporal dynamics, in particular, the flow of oxygenated blood, we have developed a convolutive ICA approach: spatial complex ICA applied to frequency-domain fMRI data. In several frequency-bands, we identify components pertaining to activity in primary visual cortex (V1) and blood supply vessels. One such component, obtained in the 0.10 Hz band, is analyzed in detail and found to likely reflect flow of oxygenated blood in V1.","72":"Aplysia feeding behavior is highly variable from cycle to cycle. In some cycles, when the variability causes a mismatch between the animal's movements and the requirements of the feeding task, the variability makes the behavior unsuccessful. We propose that the behavior is variable nevertheless because the variability serves a higher-order functional purpose. When the animal is faced with a new and only imperfectly known feeding task in each cycle, the variability implements a trial-and-error search through the space of possible feeding movements. Over many cycles, this may be the animal's optimal strategy in an uncertain and changing feeding environment.","73":"Neural models of contextual integration typically incorporate a mean firing rate representation. We examine representation of the full spike count distribution, and its usefulness in explaining contextual integration of color stimuli in primary visual cortex. Specifically, we demonstrate that a factorizable model conditioned on the number of spikes can account for both the onset and sustained portions of the response. We also consider a simplified factorizable model that parametrizes the mean of a Gaussian distribution and incorporates a logistic nonlinearity. The model can account for the sustained response but does not fair as well in accounting for onset nonlinearities. We discuss implications for neural coding.","74":"A need is identified to build models of the central nervous system that are semi-complete, applied within multiple contexts to multiple tasks, using methodologies that span multiple levels of abstraction. The issues and constraints in building such models are discussed with respect to completeness, validation, cost, scalability and robustness. An approach currently being explored is described that is suited to the creation of large heterogenous models by small independently collaborating research groups. It is based on a network model interface, a software wrapper that abstracts the interaction between a generic component and a generic framework.","75":"Responses of neurons in monkey visual cortex are modulated when attention is directed into the receptive field of the neuron: the gain or sensitivity of the response is increased or the synchronization of the spikes to the local field potential (LFP) is increased. We investigated, using model simulations, whether the synchrony of inhibitory networks could link these observations. We found that, indeed, an increase in inhibitory synchrony could enhance the coherence of the model neurons with the simulated LFP, and could have different effects on the firing rate. When the firing rate vs. current (f-I) response curves saturated at high I, attention yielded a shift in sensitivity; alternatively, when the f-I curves were non-saturating, the most significant effect was on the gain of the response. This suggests that attention may act through changes in the synchrony of inhibitory networks.","76":"The vestibuloocular reflex (VOR) in concert with the optokinetic response (OKR) stabilizes vision during head motion. The VOR system characteristics are both compensatory and adaptively self-calibrated. A model was constructed to aid in the understanding of the roles of the cerebellum and other neuronal sites in the performance and adaptation of the vertical VOR. The model structure was based upon the known neuroanatomy, and model parameters were estimated using experimental data. The model can reproduce and predict eye movements and cerebellar Purkinje cell firing patterns during VOR, OKR, and various visual-vestibular mismatch paradigms.","77":"In primates, most LGN fibers terminate in cortical layer 4C, an anatomically prominent structure of unexplained function. We hypothesize that the enormous number of cells in layer 4C of monkey primate visual cortex functions as a neural network \"hidden layer\" that inverts distortions introduced by transmitting visual signals through the LGN. This hypothesis helps explain how simple cells respond (quasi-) linearly to visual inputs in spite of nonlinearities present in LGN responses. Linearization averts prematurely discarding visual information, in keeping with the role of primary visual cortex as the source of raw visual information to the rest of the brain.","78":"In many neural systems, independently encoded information must at some point be transmitted over the spike train of one neuron. We introduce a method for quantitatively studying the effects of the signal encoding and transmission processes on the rates of transmission of multiple sources of information over one spike train, using the multiple access channel model from network information theory. To illustrate this method we study the effects of a small set of synaptic input patterns and input signal power spectra on the information capacity region of a simple three-neuron system.","79":"A conductance-based model for synaptic transmission and postsynaptic integration reveals how postsynaptic responses and their variability depend on the number of synaptic inputs. With increasing number of balanced stochastic excitatory and inhibitory inputs, the postsynaptic responses and their variance first increase and then decrease again. This non-linearity can be attributed to an anti-correlation between the total excitatory and inhibitory currents. The anti-correlation, which occurs even though the conductances of the individual synapses vary independently of each other, is determined by the total synaptic conductance and grows with the number of inputs. As the number of inputs increases, the membrane potential comes increasingly closer to the resting level.","80":"The brain produces dynamical rhythms at many frequencies that shift in amplitude and phase. To understand the functional consequences of mixtures of oscillations at the single cell level, we recorded the spike trains from single rat cortical neurons in vitro in response to two mixed sine wave currents. The reliability of spike timing was measured as a function of the relative power, phase and frequencies of the sine wave mixture. Peaks in the reliability were observed at a preferred phase difference, frequency and relative power. These results have a natural interpretation in terms of spike train attractors and bifurcations.","81":"We introduce a new correlation-based measure of spike timing reliability. Unlike other measures, it does not require the definition of a posteriori \"events\". It relies on only one parameter, which relates to the timescale of spike timing precision. We test the measure on surrogate data sets with varying amounts of spike time jitter, and missing or additional spikes, and compare it with a widely used histogram-based measure. The measure is efficient and faithful in characterizing spike timing reliability and produces smaller errors in the reliability estimate than the histogram-based measure based on the same number of trials.","82":"The otolith organs in the vestibular system are excellent detectors of linear accelerations. However, any measurement of linear acceleration is ambiguous between a tilt in a gravitational field and an inertial acceleration. Angelaki et al. have put forward a general hypothesis about how inertial accelerations can be computed based on vestibular signals (J. Neurosci. 19 (1999) 316). We have constructed a realistic, detailed model of the relevant systems to test this hypothesis. The model produces useful predictions about what kinds of neurons should be found in the vestibular nucleus if such a computation is actually performed in the vestibular system. The model is constructed using general principles of neurobiological simulation (J. Neurophys. 84 (2000) 2113).","83":"Receptive fields are commonly used to describe spatial characteristics of sensory neuron responses. They can be extended to characterize temporal or dynamical aspects by mapping neural responses in dynamical state spaces. The state-space receptive field of a neuron is the probability distribution of the dynamical state of the stimulus-generating system conditioned upon the occurrence of a spike. We have computed state-space receptive fields for semicircular canal afferent neurons in the bullfrog (Rana catesbeiana). We recorded spike times during broad-band Gaussian noise rotational velocity stimuli, computed the frequency distribution of head states at spike times, and normalized these to obtain conditional pdfs for the state. These state-space receptive fields quantify what the brain can deduce about the dynamical state of the head when a single spike arrives from the periphery.","84":"We have developed a neural system identification method for fitting models to stimulus-response data, where the response is a spike train. The method involves using a general nonlinear optimisation procedure to fit models in the time domain. We have applied the method to model bullfrog semicircular canal afferent neuron responses during naturalistic, broad-band head rotations. These neurons respond in diverse ways, but a simple four parameter class of models elegantly accounts for the various types of responses observed.","85":"The population vector is a linear decoder for an ensemble of neurons, whose response properties are nonlinear functions of the input vector. However, previous analyses of this decoder seem to have missed the observation that the population vector can also be used to estimate functions of the input vector. We explore the use of singular value decomposition to delineate the set of functions which are linearly decodable from a given population of noisy neurons."},"articletitle":{"0":"Comparison and ensemble of 2D and 3D approaches for COVID-19 detection in CT images.","1":"Calibrating the Adaptive Learning Rate to Improve Convergence of ADAM.","2":"Multi-modal trained artificial intelligence solution to triage chest X-ray for COVID-19 using pristine ground-truth, versus radiologists.","3":"Automatic Whole Slide Pathology Image Diagnosis Framework via Unit Stochastic Selection and Attention Fusion.","4":"A fuzzy-enhanced deep learning approach for early detection of Covid-19 pneumonia from portable chest X-ray images.","5":"Digital twins based on bidirectional LSTM and GAN for modelling the COVID-19 pandemic.","6":"Time series predicting of COVID-19 based on deep learning.","7":"Information Capacity of a Stochastically Responding Neuron Assembly.","8":"Fusion of intelligent learning for COVID-19: A state-of-the-art review and analysis on real medical data.","9":"Deep supervised learning using self-adaptive auxiliary loss for COVID-19 diagnosis from imbalanced CT images.","10":"DNF: A differential network flow method to identify rewiring drivers for gene regulatory networks.","11":"MANet: A two-stage deep learning method for classification of COVID-19 from Chest X-ray images.","12":"ResGNet-C: A graph convolutional neural network for detection of COVID-19.","13":"Towards simulations of long-term behavior of neural networks: Modeling synaptic plasticity of connections within and between human brain regions.","14":"Region of Interest Selection for Functional Features.","15":"Syntactically-informed word representations from graph neural network.","16":"Survey on Deep Neural Networks in Speech and Vision Systems.","17":"Multi-path x-D Recurrent Neural Networks for Collaborative Image Classification.","18":"Anatomical Context Protects Deep Learning from Adversarial Perturbations in Medical Imaging.","19":"Deep Learning for Variational Multimodality Tumor Segmentation in PET\/CT.","20":"A hierarchical temporal attention-based LSTM encoder-decoder model for individual mobility prediction.","21":"Covariate shift estimation based adaptive ensemble learning for handling non-stationarity in motor imagery related EEG-based brain-computer interface.","22":"Caching mechanisms for habit formation in Active Inference.","23":"Aleatoric uncertainty estimation with test-time augmentation for medical image segmentation with convolutional neural networks.","24":"Fast and scalable distributed deep convolutional autoencoder for fMRI big data analytics.","25":"Machine Learning on Sequential Data Using a Recurrent Weighted Average.","26":"Influence Function and Robust Variant of Kernel Canonical Correlation Analysis.","27":"Dynamic parallelism for synaptic updating in GPU-accelerated spiking neural network simulations.","28":"A sparse representation and dictionary learning based algorithm for image restoration in the presence of Rician noise.","29":"Lane Marking Detection via Deep Convolutional Neural Network.","30":"A new Mumford-Shah total variation minimization based model for sparse-view x-ray computed tomography image reconstruction.","31":"Deep Learning for Classification of Normal Swallows in Adults.","32":"Scalable Joint Segmentation and Registration Framework for Infant Brain Images.","33":"A simple plug-in bagging ensemble based on threshold-moving for classifying binary and multiclass imbalanced data.","34":"Deep Auto-context Convolutional Neural Networks for Standard-Dose PET Image Estimation from Low-Dose PET\/MRI.","35":"TENDER: Tensor non-local deconvolution enabled radiation reduction in CT perfusion.","36":"A Deep Convolutional Neural Network for segmenting and classifying epithelial and stromal regions in histopathological images.","37":"Concatenated Spatially-localized Random Forests for Hippocampus Labeling in Adult and Infant MR Brain Images.","38":"Dictionary Pruning with Visual Word Significance for Medical Image Retrieval.","39":"Low-dose cerebral perfusion computed tomography image restoration via low-rank and total variation regularizations.","40":"Denoising Magnetic Resonance Images Using Collaborative Non-Local Means.","41":"ARCH: Adaptive recurrent-convolutional hybrid networks for long-term action recognition.","42":"The general critical analysis for continuous-time UPPAM recurrent neural networks.","43":"A Learning-Based CT Prostate Segmentation Method via Joint Transductive Feature Selection and Regression.","44":"A Phase-Locked Loop Epilepsy Network Emulator.","45":null,"46":"Motion sequence analysis in the presence of figural cues.","47":"Identifying Quantitative In Vivo Multi-Parametric MRI Features For Treatment Related Changes after Laser Interstitial Thermal Therapy of Prostate Cancer.","48":"A Domain Constrained Deformable (DoCD) Model for Co-registration of Pre- and Post-Radiated Prostate MRI.","49":"A Learning Based Fiducial-driven Registration Scheme for Evaluating Laser Ablation Changes in Neurological Disorders.","50":"Abnormal Image Detection in Endoscopy Videos Using a Filter Bank and Local Binary Patterns.","51":"Possibilities offered by implantable miniaturized cuff-electrodes for insect neurophysiology.","52":"Sharing and Integration of Cognitive Neuroscience Data: Metric and Pattern Matching across Heterogeneous ERP Datasets.","53":"Computational Analysis of Muscular Dystrophy Sub-types Using A Novel Integrative Scheme.","54":"Effects of long term polyarthritis and subsequent NSAID treatment on activity with disassociation of tactile allodynia in the mouse.","55":"","56":"Coupling Time Decoding and Trajectory Decoding using a Target-Included Model in the Motor Cortex.","57":"Physical Activity Recognition Based on Motion in Images Acquired by a Wearable Camera.","58":"Oscillation in a Network Model of Neocortex.","59":"A neural model for the integration of stereopsis and motion parallax in structure-from-motion.","60":"Modeling Recovery of Rhythmic Activity: Hypothesis for the role of a calcium pump.","61":"Neuromodulation of short-term synaptic dynamics examined in a mechanistic model based on kinetics of calcium currents.","62":"Functional penetration of variability of motor neuron spike timing through a modulated neuromuscular system.","63":"Switching between gamma and theta: Dynamic network control using subthreshold electric fields.","64":"Short-Term Plasticity in a Computational Model of the Tail-Withdrawal Circuit in Aplysia.","65":"A probabilistic model of eye movements in concept formation.","66":"Segmentation of Textures Defined on Flat vs. Layered Surfaces using Neural Networks: Comparison of 2D vs. 3D Representations.","67":"Decoding modulation of the neuromuscular transform.","68":"Theta-Modulated Input Reduces Intrinsic Gamma Oscillations in a Hippocampal Model.","69":"Resonance tuning of a neuromechanical system with two negative sensory feedback configurations.","70":"Combining synaptic and cellular resonance in a feed-forward neuronal network.","71":"Spatio-temporal dynamics in fMRI recordings revealed with complex independent component analysis.","72":"Cycle-to-cycle variability as an optimal behavioral strategy.","73":"Spike count distributions, factorizability, and contextual effects in area V1.","74":"Neural systems integration.","75":"Synchronization as a mechanism for attentional gain modulation.","76":"A dynamical model for the vertical vestibuloocular reflex and optokinetic response in primate.","77":"Layer 4C in monkey V1 may linearize the output of the LGN.","78":"The neural multiple access channel.","79":"Variability of postsynaptic responses depends non-linearly on the number of synaptic inputs.","80":"Reliability and bifurcation in neurons driven by multiple sinusoids.","81":"A new correlation-based measure of spike timing reliability.","82":"A general framework for neurobiological modeling: an application to the vestibular system.","83":"State-space receptive fields of semicircular canal afferent neurons in the bullfrog.","84":"Modelling the firing pattern of bullfrog vestibular neurons responding to naturalistic stimuli.","85":"Linearly decodable functions from neural population codes."},"doi":{"0":"","1":"","2":"","3":"","4":"","5":"","6":"","7":"","8":"","9":"","10":"","11":"","12":"","13":"","14":"","15":"","16":"","17":"","18":"","19":"","20":"","21":"","22":"","23":"","24":"","25":"","26":"","27":"","28":"","29":"","30":"","31":"","32":"","33":"","34":"","35":"","36":"","37":"","38":"","39":"","40":"","41":"","42":"","43":"","44":"","45":"","46":"","47":"","48":"","49":"","50":"","51":"","52":"","53":"","54":"","55":"","56":"","57":"","58":"","59":"","60":"","61":"","62":"","63":"","64":"","65":"","66":"","67":"","68":"","69":"","70":"","71":"","72":"","73":"","74":"","75":"","76":"","77":"","78":"","79":"","80":"","81":"","82":"","83":"","84":"","85":""},"journal_title":{"0":"Neurocomputing","1":"Neurocomputing","2":"Neurocomputing","3":"Neurocomputing","4":"Neurocomputing","5":"Neurocomputing","6":"Neurocomputing","7":"Neurocomputing","8":"Neurocomputing","9":"Neurocomputing","10":"Neurocomputing","11":"Neurocomputing","12":"Neurocomputing","13":"Neurocomputing","14":"Neurocomputing","15":"Neurocomputing","16":"Neurocomputing","17":"Neurocomputing","18":"Neurocomputing","19":"Neurocomputing","20":"Neurocomputing","21":"Neurocomputing","22":"Neurocomputing","23":"Neurocomputing","24":"Neurocomputing","25":"Neurocomputing","26":"Neurocomputing","27":"Neurocomputing","28":"Neurocomputing","29":"Neurocomputing","30":"Neurocomputing","31":"Neurocomputing","32":"Neurocomputing","33":"Neurocomputing","34":"Neurocomputing","35":"Neurocomputing","36":"Neurocomputing","37":"Neurocomputing","38":"Neurocomputing","39":"Neurocomputing","40":"Neurocomputing","41":"Neurocomputing","42":"Neurocomputing","43":"Neurocomputing","44":"Neurocomputing","45":"Neurocomputing","46":"Neurocomputing","47":"Neurocomputing","48":"Neurocomputing","49":"Neurocomputing","50":"Neurocomputing","51":"Neurocomputing","52":"Neurocomputing","53":"Neurocomputing","54":"Neurocomputing","55":"Neurocomputing","56":"Neurocomputing","57":"Neurocomputing","58":"Neurocomputing","59":"Neurocomputing","60":"Neurocomputing","61":"Neurocomputing","62":"Neurocomputing","63":"Neurocomputing","64":"Neurocomputing","65":"Neurocomputing","66":"Neurocomputing","67":"Neurocomputing","68":"Neurocomputing","69":"Neurocomputing","70":"Neurocomputing","71":"Neurocomputing","72":"Neurocomputing","73":"Neurocomputing","74":"Neurocomputing","75":"Neurocomputing","76":"Neurocomputing","77":"Neurocomputing","78":"Neurocomputing","79":"Neurocomputing","80":"Neurocomputing","81":"Neurocomputing","82":"Neurocomputing","83":"Neurocomputing","84":"Neurocomputing","85":"Neurocomputing"},"keyword":{"0":"COVID-19Computed TomographyDeep LearningDetectionEnsemble","1":"ADAMAdaptive methodsDeep learningStochastic methods","2":"Artificial intelligenceCOVID-19Multi-modalReader study","3":"Whole slide imageattention fusioncomputer-aided diagnosisstochastic selectionunits of interest","4":"Chest X-rayConvolutional Neural NetworkCovid-19Fuzzy logicPortable systemsexplainable Artificial Intelligence","5":"Deep learningDigital twinsGenerative adversarial networksLong short-term memory networksReduced order models","6":"COVID-19LSTMPredictionRNNTime series","7":"","8":"COVID-19DiagnosisIntelligent technologiesPredictionSARS-CoV-2Social distancing","9":"COVID-19ClassificationData imbalanceDeep supervised learningSelf-adaptive auxiliary loss","10":"differential network analysisinformation entropynetwork flownetwork topologyneuronal differentiation","11":"COVID-19Chest X-ray imagesConvolutional neural networksSegmentationSpatial attentionTwo-stage","12":"COVID-19Deep learningGraph neural networkPneumoniaResGNet-C","13":"Biological neural network modelingBrain simulationNeural mass modelOptimization","14":"Feature SelectionFunctional DataMachine Learning","15":"Contextual word representationNatural language processingSyntactic word representationWord embeddingWord representation","16":"Vision processingcomputational intelligencecomputer visionconvolutional neural networksdeep autoencodersdeep learningembedded systemsgenerative neural networkshardware constraintsnatural language processingspeech recognition","17":"RNNcategory-irrelevant attributeslongitudinalunordered image","18":"","19":"PET\/CT imagesTumor segmentationdeep learninginformation fusionvariational method","20":"Human mobilityLSTM encoder-decoder modelMobility predictionSequence predictionTemporal attentionTravel regularity","21":"BCI, Brain-computer-interfaceBrain-computer interface (BCI)CS, Covariate shiftCSA, Covariate shift adaptationCSE, Covariate shift estimationCSE-UAEL, CSE-based unsupervised adaptive ensemble learningCSP, Common spatial patternCSV, Covariate shift validationCSW, Covariate shift warningCovariate shiftDWEC, Dynamically weighted ensemble classificationEEG, ElectroencephalographyERD, SynchronizationERS, DesynchronizationEWMA, exponential weighted moving averageElectroencephalogram (EEG)Ensemble learningFB, Frequency bandFBCSP, Filter bank common spatial patternKNN, K-nearest-neighborsLDA, Linear discriminant analysisMI, Motor imageryNSL, Non-stationary learningNon-stationary learningPCA, Principal component analysisPWKNN, Probabilistic weighted K-nearest neighbourRSM, Random subspace methodSSL, Semi-supervised learning","22":"Active InferenceCachingDeliberative controlHabitisationHabitual control","23":"Convolutional neural networksData augmentationMedical image segmentationUncertainty estimation","24":"Data miningDistributed computing methodologiesMachine learningNeural networks","25":"Attention MechanismRecurrent Neural NetworkSequences","26":"Influence functionKernel (coss-) covariance operatorKernel methodsRobustnessand Imaging genetics analysis","27":"Dynamic parallelismGraphical processing unit (GPU)SimulationsSpiking neural network","28":"Rician noisede-noisingdictionariessparse representations","29":"Computer VisionDeep LearningImage ProcessingIntelligent Transportation SystemsLane Marking Detection","30":"Mumford-Shah total variationcomputer tomographyimage reconstructionsparse-view","31":"cervical auscultationclassificationdeep learningdysphagia","32":"Joint segmentation and registrationand infant brain MR imageslongitudinal growth trajectorymulti-atlas patch based label fusion","33":"Bagging ensemblesBinary classificationImbalanced dataMulticlass classificationPosterior calibrationResampling","34":"Auto-context strategyDeep convolutional neural networkPET image restoration","35":"CT perfusionLow radiation doseStrokeTensor non-local deconvolutionTotal variation","36":"Breast histopathologyColorectal cancerDeep Convolutional Neural NetworksFeature representationThe classification of epithelial and stromal regions","37":"Image segmentationatlas selectionbrain MR imagesclusteringrandom forest","38":"BoVWDictionary pruningMedical image retrieval","39":"Cerebral perfusion CTLow-doseLow-rankRegularizationTotal variation","40":"Block MatchingDenoisingNon-Local MeansNon-Parametric Regression","41":"Action recognitionDeep learningHybrid feature learning","42":"Continuous-time recurrent neural networkdynamical analysisgeneral critical conditionuniformly pseudo-projection-anti-monotone network","43":"","44":"approximate entropyelectrocorticographyepilepsy emulationneural networkphase locked loop","45":"Concentration of distancesFractional normsHigh-dimensional data analysisHubness","46":"3D-structure-from-motionfigural cuesform-cuesmotionmotion-impaired-patientsstroke patientsstructure-from-motion","47":"focal treatmentlaser interstitial thermal therapymulti-parametric MRIprostate cancerregistrationtreatment changetreatment evaluation","48":"","49":"Fiducial-driven image registrationbrain MRIlaser-induced interstitial thermal therapyminimally invasive therapy","50":"ColonoscopyFilter bankLocal binary patternTextonTexton dictionaryWireless capsule endoscopy","51":"Cuff-electrodeNeural interfaceNeuroethologyNeuronal signalsSensory physiology","52":"","53":"","54":"","55":"","56":"","57":"","58":"","59":"","60":"","61":"","62":"","63":"","64":"","65":"","66":"","67":"","68":"","69":"","70":"","71":"","72":"","73":"","74":"","75":"","76":"","77":"DistortionLayer 4NonlinearityVisual cortex","78":"Multiple access channelNeural systemsSignal encodingTransmission","79":"","80":"","81":"","82":"","83":"NASA Discipline NeuroscienceNon-NASA Center","84":"NASA Discipline NeuroscienceNon-NASA Center","85":"Population codesPrincipal componentsSingular value decomposition"},"pmid":{"0":35345875,"1":35342226,"2":35185296,"3":35082453,"4":35079203,"5":34703079,"6":34690432,"7":34539080,"8":34149184,"9":34121811,"10":34025035,"11":33753962,"12":33390662,"13":33250573,"14":33162675,"15":33162674,"16":33100581,"17":32863584,"18":32863583,"19":32773965,"20":32501365,"21":32226230,"22":32055104,"23":31595105,"24":31354187,"25":30799908,"26":30416263,"27":30245550,"28":30214129,"29":29887672,"30":29805200,"31":29755210,"32":29416227,"33":29398782,"34":29217875,"35":32523255,"36":28154470,"37":28133417,"38":27688597,"39":27440948,"40":26949289,"41":29290647,"42":26858512,"43":26752809,"44":26664133,"45":26640321,"46":26028822,"47":25346574,"48":25267873,"49":25225455,"50":25132723,"51":23576843,"52":22844185,"53":22773895,"54":22547902,"55":22505792,"56":22379284,"57":21779142,"58":20368744,"59":19255615,"60":18516214,"61":18516212,"62":18516210,"63":18185843,"64":17957237,"65":22787288,"66":19562098,"67":19763188,"68":19593393,"69":19584947,"70":19079739,"71":20689619,"72":19830256,"73":21113307,"74":20827442,"75":20802816,"76":12934604,"77":32153320,"78":32153319,"79":20871738,"80":20871737,"81":20740049,"82":12744262,"83":12194188,"84":12194187,"85":32153318},"pubdate_year":{"0":2022,"1":2022,"2":2022,"3":2021,"4":2022,"5":2022,"6":2022,"7":2021,"8":2021,"9":2021,"10":2020,"11":2021,"12":2021,"13":2020,"14":2021,"15":2020,"16":2020,"17":2020,"18":2020,"19":2020,"20":2020,"21":2019,"22":2019,"23":2019,"24":2019,"25":2019,"26":2018,"27":2018,"28":2018,"29":2018,"30":2018,"31":2018,"32":2017,"33":2018,"34":2017,"35":2017,"36":2016,"37":2017,"38":2016,"39":2016,"40":2016,"41":2016,"42":2016,"43":2016,"44":2016,"45":2015,"46":2015,"47":2014,"48":2014,"49":2014,"50":2014,"51":2012,"52":2012,"53":2012,"54":2012,"55":2012,"56":2012,"57":2011,"58":2010,"59":2008,"60":2007,"61":2007,"62":2007,"63":2007,"64":2007,"65":2007,"66":2007,"67":2007,"68":2007,"69":2007,"70":2007,"71":2006,"72":2006,"73":2004,"74":2004,"75":2004,"76":2003,"77":2003,"78":2003,"79":2003,"80":2003,"81":2003,"82":2002,"83":2001,"84":1999,"85":2002}}